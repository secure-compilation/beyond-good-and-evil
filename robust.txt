* Robust compilation

Goal: we want a (probably) weaker notion of secure compilation that
only captures the integrity aspect of it (e.g. data invariants) and
leaves out the confidentiality aspect. This should be easier to obtain
and thus should reduce the enforcement overhead.

In terms of reasoning, we want to use a (non-relational!) program
logic to prove robust safety properties and have these properties be
preserved by the compiler to the target level.

* Stating robust compilation [the hard part]

forall P. P  robustly safe ->
          P↓ robustly safe

forall P. (forall C. P  safe for C) ->
          (forall c. P↓ safe for c)

P safe for C  iff  C[P] is only unsafe because of C  (blame variant)

All this is parameterized by notions of being "safe" at the source and
at the target levels. There are probably both intrinsic (asserts) and
extrinsic (traces) ways to define safety. The safety notions at the
source and target level must "match".

** TODO Intrinsic (asserts)
** TODO Extrinsic (execution traces)

P satisfies property Prop despite C

** Extrinsic (state invariants, seems strictly weaker)

P has invariant I despite C

forall executions of C[P]:
S₁ → S₂ → ... → Sₙ
we have I(S₁) ∧  ... ∧ I(Sₙ)
- where we somehow need to restrict I to the program's part of the state
- we somehow need to port this invariant to the low level, where the
  states are very different: so we need something like a simulation
  relation, but only on the program's part of the state

** TODO Trying to state something in terms of backward simulation

*** Take 3: just mapping contexts
Compiler ↓ is "R-good" iff
∀P. ∀c. ∃C. so that "c[P↓] R-simulates C[P]", i.e.
1. (c[P↓],C[P]) ∈ R
2. ∀s s' S. s → s' so that (s,S) ∈ R
   a. (s',S) ∈ R
   b. ∃S'. S → S' and (s',S') ∈ R

The magic projection is just hidden in R, not gone, right?

*** Take 2: mapping contexts + magically projecting
Compiler ↓ is "R-good" iff
∀c. ∃C. so that "c[P↓] R-simulates C[P]", i.e.
1. (P↓,P) ∈ R
2. ∀s s' S. s → s' so that (prog(s),prog(S)) ∈ R
   a. (prog(s'),prog(S)) ∈ R
   b. ∃S'. S → S' and (prof(s'),prog(S')) ∈ R
- where prog(.) is a magic way to project out the program part
  and throw away the context part

*** Take 1
Compiler ↓ is "good" iff
∃R a relation on execution states so that
1. ∀C. (C[P],??[P↓]) ∈ R  – what should the ?? be though? C↓?
                          – do we want context mapping ∀c. ... ∃C...?
2. ∀(S,s) ∈ R. s → s' ⇒
   a. this is a context step and (S,s') ∈ R
OR b. this is a program step and
      a.1. ∃S'. S → S' and (S',s')
      a.2. (S,s') ∈ R      – allow silent program steps?
3. ???   – need more conditions, otherwise full relation would do?
– Still unclear whether there is any way to force R to be sensible.
  For instance R should only care about the program's part of state.
  + Generally in simulation proofs the definition of R matters,
    it's part of the statement and can't be hidden behind ∃
– Beyond relaying on distinguishing program and context steps,
  we only require that the context can't break R in any way

This looks like at most a proof technique than like a final theorem.

This might be stronger than compiler correctness
(even in the "separate compilation" and "compositional" setting)

** Stating this in terms of interaction traces

If one was willing to trust some trace semantics capturing the
interaction between the program and the context, then the property can
be restated as:

forall P. traces(P) ⊇ traces(P↓)

One nice thing with this is that it allows refinement of
nondeterminism in the compiler.

Another nice thing is that any properties over these interaction
traces are clearly preserved by compilation,
i.e. from Prop ⊇ traces(P) we directly get Prop ⊇ traces(P↓)
[If we also look at infinite traces we might even go beyond safety
 to arbitrary trace properties (i.e. safety + liveness)]

The main problem is that I don't want to trust 2 trace semantics. So
while this might be a nice proof technique for proving robust safety,
I would like to avoid having this as the definition.

So what should we require of the trace semantics to get rid of them?
- looking at how the two trace semantics are used we probably only
  need "soundness" for one and "completeness" for the other (although
  it would be quite strange if we wouldn't have the dual properties too)
- this should in any case be weaker/different than fully abstract
  trace semantics, where they care about contextual equivalence:
    traces(P) = traces(Q) ⇔ ∀C. C[P] ∼ C[Q]
  http://www.mpi-sws.org/~marcopat/marcopat/Publications_files/llfatr-j.pdf
  http://ect.bell-labs.com/who/ajeffrey/papers/esop05.pdf
  + "soundness" and "completeness" already taken in this setting:
    + soundness:    traces(P) ⊆ traces(Q) ⇒ ∀C. C[P]↓ ⇒ C[Q]↓
    + completeness: (∀C. C[P]↓ ⇒ C[Q]↓)   ⇒ traces(P) ⊆ traces(Q)
- the properties we're looking for are not relational
- they could be related to trace decomposition and composition;
  here are some lame attempts:
  + t ∈ traces(P) ⇒ ∃C. t⁻¹ ∈ traces(C) and C[P] "can execute along trace t"
  + C[P] →* S ⇒ ∃t. "corresponding to this interaction" so that
                    t ∈ traces(P) ∧ t ∈ traces(C)
  + one difficulty in defining these is that we don't have a "barb"
    like termination, while in FA these are defined in terms of that
  + a missing thing above is extracting an interaction trace from a
    program execution

Thee granularity of this is much coarser than properties that talk
about execution traces; this might still follow from those though?

* More complex context mapping? or not ...

How would context mapping work for robust compilation? Say if c reads
all of P↓'s memory, which should be intuitively allowed by our
definition, the context C we produce has to simply guess all that
information?
- So our mapping of contexts needs to depend not only on the low-level
  contexts, but also on the program P and on the whole compiler–which
  wasn't the case for full abstraction, right???
  - so could it be that robust compilation is in general
    *more difficult* to prove than full abstraction?
- wouldn't mapping interaction traces simplify this too though?

* Gordon-Jeffrey:

P is robustly safe iff
forall C. C[P] is safe
- syntactic restriction on contexts
  - where only P can break safety
  - C is assertion free -> C cannot break safety

For them a whole program is safe is all asserts follow dynamically
from the active assumes. Their type system ensures safety and robust
safety statically. They have no compiler.

In a setting like this in which integrity is obtained
cryptographically using secret keys it could be that robust
compilation is as hard to get as fully abstract one.

They add syntactic assert statements, that prove certain (robust)
safety properties of the program.

* One similar phenomenon from CSF submission: defined behavior

Being defined is a safety property of whole source programs
- it can be stated in terms of not reaching certain stuck states

Difference to robust compilation:
- we don't have a notion of being (un)defined in the target,
  so "preserving defined behavior" makes no sense here
- things could be different in CompCert, where up to a certain point
  the intermediate languages involved will still have a notion of
  (un)defined behavior, and the compiler steps have to preserve that
  + undefined behavior due to the memory safety violations is probably
    carried all the way to the target, because even the target ASM of
    CompCert seems to use the same memory model

fully defined =? robustly defined
- not simple to prevent the context from causing undefined behavior
  + semantic dual restriction on contexts
- we break program-context circularity using blame

* Patrignani

For them robust compilation seems much easier to obtain than full
abstraction, since they could for instance allow pointers to be passed
out without being turned into handlers. Distinguishing pointers
(e.g. comparing them for equality) would probably not cause problems
for robust compilation. At the same time they still need a way to
preserve the integrity of pointers ... which they also achieve with
handlers. Instead they could just cryptographically sign/MAC pointers
or keep a big hash table with all the valid pointers that escape.

* Micro-policies

Robust compilation would at least save us from having to hide sizes of
things and we can allow side- and covert-channels. Hopefully we can
prove full abstraction without side-channels and robust compilation
with them.

We no longer need to do register cleaning, but we still need to
restore our registers when we regain control.

* Biorthogonality

The relation between this and biorthogonality is still very intriguing.

Biorthogonality, Step-Indexing and Compiler Correctness
Nick Benton, Chung-Kil Hur
http://sf.snu.ac.kr/gil.hur/publications/realize.pdf

* Old notes (2015-09-10)
** Exit = external observation caused only by program

∀P. ∃c not including exit. c[P↓] exits ⇒
    ∃C not including exit. C[P ] exits

Not sure this is strong enough to be our property,
but it looks like a very sensible corollary to expect.

One way to instantiate this is with a program that detects its
invariant being broken and only then aborts. This only works for
dynamically checkable invariants though.

This form of weak integrity preservation seems related to weak secrecy
preservation in process calculi (with fresh channel creation):
∀P. ∃c. (c | νx. P↓) outputs x ⇒
    ∃C. (C | νx. P)  outputs x
Here the contexts can only find out x if the program leaks it.

** TODO some more ideas there (see Google doc)

* Q: Does robust compilation allow refinement of non-determinism?

What exactly is it about FA that prevents refinement of non-determinism?
Would dropping the boring FA direction help with this, for instance?

Refinement of non-determinism seems useful for modeling implementation
defined behaviors in the C source semantics. The alternative we would
need now is to expose all implementation choices in the source semantics.

* References

Original robust safety work:
http://ect.bell-labs.com/who/ajeffrey/papers/jcs03.pdf:
- "We are mainly concerned not just with safety, but with safety in
  the presence of an arbitrary hostile opponent, which we call robust
  safety. (This use of "robust" to describe a property invariant under
  composition with an arbitrary environment follows Grumberg and
  Long [20])"

[20] O. Grumberg and D.E. Long. Model checking and modular verification. ACM
Transactions on Programming Languages and Systems, 16(3):843–871, 1994.
http://www.cse.usf.edu/~zheng/lib/verification/compositional/grumberg-modular94.pdf

David Swasey and Derek Dreyer ongoing work on robust safety in Iris
(should ask them for a copy after ICFP)
http://www.mpi-sws.org/~swasey/

Quantification of Integrity. Mathematical Structures in Computer
Science, 25(2):207-258, 2015. Michael R. Clarkson, Fred B. Schneider.
https://www.cs.cornell.edu/~clarkson/papers/clarkson_integrity_journal.pdf
